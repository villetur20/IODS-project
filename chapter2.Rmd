# Week2 Ville Turppo

*Describe the work you have done this week and summarize your learning.*

- Describe your work and results clearly. 
- Assume the reader has an introductory course level understanding of writing and reading R code as well as statistical methods.
- Assume the reader has no previous knowledge of your data or the more advanced methods you are using.




Here I'm opening the data from the internet. Sep tells R the seperator used in the data, header means there is a header.
```{r}
AA <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep = ",", header = TRUE)
str(AA)
dim(AA)
```

str command shows that the data has 7 variables and 166 rows.There are character(gender), integer(age/points) and numeric (the rest of variables) in the data.

Library commands tell R to open libraries for the plot commands. First the ggplot2 and GGally packages need to be installed.
```{r}
library(ggplot2)
library(GGally)
```


This plot opens graphical overview of the data (e.g. distribution) and numerical values like correlation (i.e. how much the variables are related to one another. 0= no correlation, closer to 1 or -1 means the variables are more related)
For example it seems that attitude is more related to points than age.

```{r}
X <- ggpairs(AA)
X
D <- ggpairs(AA, mapping = aes(col = gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))
D
```


I choose attitude, stra and surf as explanatory variables. P values for stra and surf had p>0.05 and thus low statistical relation with these variables and points. 
These two were excluded and simple regression with points and attitude are shown below.
Fitted model: there seems to be statictically significant (low P value) relation between points and attitude.


```{r}
SS <- lm(points ~ attitude + stra + surf, data = AA)
summary(SS)
FF <- lm(points ~ attitude, data = AA)
summary(FF)
```


I learnt the following about R-squared from the internet today:
R-squared is the percentage of the dependent variable variation that a linear model explains.
100% represents a model that explains all of the variation in the response variable around its mean.
Adjusted R-squared provides the same information as R-squared but adjusts for the number of terms in the model.
Plot command makes the following diagnostic plots and par command puts them on the same page.

```{r}
par(mfrow = c(2,2))
plot(SS, which = c(1,2,5))
E <- lm(points ~ attitude + stra + surf, data = AA)
par(mfrow = c(2,2))
plot(E, which = c(1,2,5))
```



Q-Q plot shows that both genders have same distribution.

Residuals Vs fitted: Residuals = Observed value â€“ Fitted value. Y-axis= residual, X-axis= fitted values. Unwanted patterns of this plot = we can't trust the test. The should't be patterns. You shouldn't be able to predict the residual with fitted value, if the data is truly random.

Residuals vs leverage: can also be used to detect heteroskedasticity and non-linearity. Second, points with high leverage may be influential: that is, deleting them would change the model a lot. Points outside Cook's distance have high influence.

Now there are few points outside Cook's distance, that could affect leverage and the model.
