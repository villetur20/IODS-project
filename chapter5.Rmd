---
title: "chapter5.Rmd"
output: html_document
---
# Week 5 Analysis Ville Turppo

Loading data

```{r}
library(GGally)
library(dplyr)
library(corrplot)
x <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human2.txt", sep = "," , header = TRUE)
```


## 1) Visualizing the data and variable summaries.

```{r}
ggpairs(x)
cor(x) %>% corrplot
summary(x)
```

## 2) PCA on NOT stadardized data

```{r}
pca_x <- prcomp(x)
biplot(pca_x, choices = 1:2, cex = c(0.8, 1), col = c("grey40", "deeppink2"))
```

## 3) Standardizing Human data "x" and then PCA biplotting.
The results are different. PCA is sensitive to the relative scaling of the original variables. Thus, original variables with larger variances are assumed to be more important.

```{r}
x_std <- scale(x)
pca_x_std <- prcomp(x_std)
biplot(pca_x_std, choices = 1:2, cex = c(0.8, 1), col = c("grey40", "deeppink2"))
```


Printing out the original and standardized Principal components
```{r}
pca_x
pca_x_std
```



## 4) Interpretations

Mat.Mor and Ado.Birth are positively correlated. As are parli and labo.FM. The rest of the variables form the third group of positively correlated variables.
When the angle between arrows is close to 90, the variables are not correlated, like Mat.Mor and Labo.FM.
When the angle between arrows is close to 180 degrees. Then the variables are negatively correlated, like Edu.Exp and Mat.Mor.

PC1 and PC2: Mat.Mor and Ado.Birth are pointing towards positive PC1 values,thus, they contribute the most to PC1. Where as, variables like Edu.Exp poit towards PC2 and contribute PC2 positively.



## 5) (see the links to the last plots) Opening libraries, checking structure and dimensions. There are 300 observations and 36 variables. 

```{r}
library(FactoMineR)
library(ggplot2)
library(tidyr)
data("tea")
str(tea)
dim(tea)
```



### Now reducing the number of variables to 6. Plus dim, str and plotting. Now there are 6 variables with 300 observations. It seems that most drink "Earl Grey" tea in chain stores.
!!! Somehow, the knit function did not work with the "select(one_of)" That's why I don't have the plot, dim or str printed out here in the diary. Below is the link to the plot.

keep_columns <- c("Tea", "How", "how", "sugar", "where", "lunch")

tea_time <- select(tea, one_of(keep_columns))

gather(tea_time) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))

str(tea_time)

dim(tea_time)

https://raw.githubusercontent.com/villetur20/IODS-project/master/Tables%20for%20RMD/palkit.png




### Multiple Correspondence Analysis (MCA) of the "tea_time"

mca <- MCA(tea_time, graph = FALSE)

summary(mca)

plot(mca, invisible=c("ind"), habillage = "quali")

https://raw.githubusercontent.com/villetur20/IODS-project/master/Tables%20for%20RMD/MCA.png



### Intepreation:

Summary table
Eigenvalues: coordinates, variances and % of the variances
Individuals: coordinates, contribution on the dimension and the squared correalations on dim.
Categories: Coordinates, contribution. The v.test (if +/- 1.96 the coordinate is significantly different from zero)
Categorical variables: If the values are close to each other, it indicates strong link between variable and dimension

MCA factor map:
Similarity: variables close to each other are more similar (e.g. sugar and no sugar). Whereas, more distant variables are not that similar (e.g. chain store and tea shop)




